#!/usr/bin/perl -w

use strict;
use Cwd 'abs_path';
use IPC::Open2;
use File::Basename;

my $processors_per_node = 8;

sub usage {
    my $p = $processors_per_node;
    print <<EOF
Usage: $0 job1.sh [job2.sh [job3.sh ...]]

Submits all your jobs scripts, but tries to combine smaller jobs
together into groups of $p to ensure that you allocate the minimum
number of nodes possible.

To use this script effectively, you must set the following line in
your job script:
#PBS -l nodes=N:ppn=P

... where N*P is the total number of processors you'd like to run your
script on.

This script also recognizes the following options in each job file:
name=name - set with '#PBS -N name'
output=out - set with '#PBS -o out'
error=err - set with '#PBS -e err'
join - set with '#PBS -j oe'

These options take the default values supplied by PBS if not specified.

EOF
;
  die join("\n",@_) . "\n" if @_;
}

usage("Please supply a job file") if not (@ARGV);

if ($ARGV[0] eq '-h' or $ARGV[0] eq '--help') {
    usage();
    exit(0);
}


# collect info about the files
my @files;
my %procs;
my %names;
my %output_directives;
my %directories;
foreach my $file (@ARGV) {
    # get the full path of the file
    my $absfile = abs_path($file);
    my ($filename, $directory, $suffix) = fileparse($absfile);
    $directories{$absfile} = $directory;

    #search through the file and get the number of processes it needs.
    open(SCRIPT, $file) or die "Can't open file $file: $!\n";
    $names{$absfile}=$file;
    my $this_proc_count = 0;
    my $join_std_err = 0;
    my $output = '';
    my $error = '';
    while (my $line = <SCRIPT>) {
	if ($line =~ /^#PBS -l nodes=(\d+):ppn=(\d+)/) {
	    my $nodes = $1;
	    my $ppn = $2;
	    $this_proc_count = $nodes*$ppn;
	}
	$names{$absfile} = $1 if $line =~ /^#PBS -N (.*)/;
	$join_std_err = 1 if $line =~ /^#PBS -j oe/;
	$output = $1 if $line =~ /^#PBS -o (.*)/;
	$error = $1 if $line =~ /^#PBS -e (.*)/;
    }
    $procs{$absfile} = $this_proc_count;
    $output_directives{$absfile} = "";
    if ($output) {
	$output_directives{$absfile} .= " >| $output";
    } else {
	$output_directives{$absfile} .= " >| $names{$absfile}.o\$PBS_JOBID";
    }
    if ($error) {
	$output_directives{$absfile} .= " 2>| $error";	
    } elsif ($join_std_err) {
	$output_directives{$absfile} .= " 2>&1";	
    } else {
	$output_directives{$absfile} .= " 2>| $names{$absfile}.e\$PBS_JOBID";	
    }
    push @files, $absfile;
}

# sort the file list by processor count mod 8.  8 => 8, not 0.
@files = sort { leftover($procs{$b}) <=> leftover($procs{$a}); } @files; 

sub leftover {
    my ($x) = @_;
    return (($x-1) % $processors_per_node)+1;
}

# bin the jobs together.  Try to minimize the total number of
#processors allocated while maximizing the number of jobs created.
my $bins = [];
foreach my $file (@files) {
    #search through all the existing bins for a place to put this job.
    my $found_free_space=0;
    foreach my $bin (@$bins) {
	if ($bin->{free} >= leftover($procs{$file})) {

	    $bin->{free} -= leftover($procs{$file});
	    push @{$bin->{files}}, $file;
	    $bin->{proc_count} += $procs{$file};

	    $found_free_space=1;
	    last;
	}
    }
    if (not $found_free_space) {
	#make a new bin.
	my $bin = {};

	$bin->{free} = $processors_per_node-leftover($procs{$file});
	$bin->{files} = [$file];
	$bin->{proc_count} = $procs{$file};

	push @$bins, $bin;
    }
}

# print out jobs for each bin.
my $counter = 0;
foreach my $bin (@$bins) {
    my @bin_files = @{$bin->{files}};
    my $job_name = join(":", @names{@bin_files});
    my $node_count = int(($bin->{proc_count}+$processors_per_node-1)/$processors_per_node);


    # write out the actual qsub script
    #open(OUTPUT, ">test$counter"); $counter++;
    open2(\*INPUT, \*OUTPUT, 'qsub');

    print OUTPUT <<EOF
#!/bin/bash

##################################
## YOU CAN SET THESE PARAMETERS ##
# Join output and error into one file
#PBS -j oe
# Name of the job that shows  up in qstat
#PBS -N $job_name
# How many nodes and processes per node to use.  
# Always use 8 to avoid wasting processors
#PBS -l nodes=$node_count:ppn=8
# Set the job to run for 10 days maximum of one day.  
# Otherwise, the maximum walltime is ridiculously short.
#PBS -l walltime=24000:00:00
##################################

cd $PBS_O_WORKDIR

export original_pbs_nodefile="\$PBS_NODEFILE"
exec 9<\$original_pbs_nodefile

nodefiles=( )
EOF
    ;

    foreach my $file (@bin_files) {
	#print out host files for each of the subscripts.
	print OUTPUT "\nexport PBS_NODEFILE=`mktemp`\n";
	print OUTPUT "nodefiles[\${#nodefiles[*]}]=\$PBS_NODEFILE\n";
	
	for (my $ii=0; $ii<$procs{$file}; $ii++) {
	    print OUTPUT "read -u9 line; echo \$line >> \$PBS_NODEFILE\n";
	}

	#set the PBS_O_WORKDIR to the location of the script.
	print OUTPUT qq|export PBS_O_WORKDIR="$directories{$file}"\n"|;
	#run the script.
	print OUTPUT "bash $file $output_directives{$file} &\n";
    }
    

    print OUTPUT <<EOF

wait

for ii in "\${nodefiles[@]}"
do
  rm -f \$ii
done

EOF
;
    close(OUTPUT);

    print <INPUT>;
    close(INPUT);
}

